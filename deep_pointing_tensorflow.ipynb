{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_pointing_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ysterin/deep-pointing/blob/master/deep_pointing_tensorflow.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "tq8eVt3H1qIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rj8iqDy62m4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e8295d3c-5b56-48b4-c8f2-5327d65583f9"
      },
      "cell_type": "code",
      "source": [
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1aOdHBIjB0fOLg9sQMhOlZI6gy_oMPHty'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "SRLWaZD029LG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "ef9a3f21-3b9b-479d-fb49-9a9fa20a3bc3"
      },
      "cell_type": "code",
      "source": [
        "{ord(c) for c in text}"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{32,\n",
              " 1456,\n",
              " 1457,\n",
              " 1458,\n",
              " 1459,\n",
              " 1460,\n",
              " 1461,\n",
              " 1462,\n",
              " 1463,\n",
              " 1464,\n",
              " 1465,\n",
              " 1466,\n",
              " 1467,\n",
              " 1468,\n",
              " 1473,\n",
              " 1474,\n",
              " 1488,\n",
              " 1489,\n",
              " 1490,\n",
              " 1491,\n",
              " 1492,\n",
              " 1493,\n",
              " 1494,\n",
              " 1495,\n",
              " 1496,\n",
              " 1497,\n",
              " 1498,\n",
              " 1499,\n",
              " 1500,\n",
              " 1501,\n",
              " 1502,\n",
              " 1503,\n",
              " 1504,\n",
              " 1505,\n",
              " 1506,\n",
              " 1507,\n",
              " 1508,\n",
              " 1509,\n",
              " 1510,\n",
              " 1511,\n",
              " 1512,\n",
              " 1513,\n",
              " 1514}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "9ZZ6W3t33RCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d35fa8a-fedb-4e4b-9f9f-d717a4c29416"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5cKWNapi85YT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "124f7b21-63a5-44d0-c03a-baacd7cd2b28"
      },
      "cell_type": "code",
      "source": [
        "def tensorize(text):\n",
        "  unpointed_text = [c for c in text if ord(c) in range(1488, 1515) or c==' '][0:]\n",
        "  pointing_seqs = re.split(r'\\w| ', text)[1:]\n",
        "  print(pointing_seqs[:100])\n",
        "  print(unpointed_text[:100])\n",
        "  \n",
        "  assert len(unpointed_text) == len(pointing_seqs)\n",
        "  N = len(unpointed_text)\n",
        "  text_ = ''\n",
        "  for i in range(N):\n",
        "    text_ += unpointed_text[i] + pointing_seqs[i]\n",
        "  assert text_==text\n",
        "  letters_index = { chr(i):i-1487 for i in range(1488, 1515)}\n",
        "  letters_index[' '] = 0\n",
        "  \n",
        "  X = np.asarray([letters_index[c] for c in unpointed_text])\n",
        "  \n",
        "  pointings = [chr(i) for i in range(1456, 1468)]\n",
        "  diphthongs = [''.join([chr(i) for i in l]) for l in [[1464, 1460], [1463, 1456], [1464, 1456], [1463, 1460]]]\n",
        "  num_pointings = len(pointings)\n",
        "  dagesh = chr(1468)\n",
        "  shin = chr(1473)\n",
        "  sin = chr(1474)\n",
        "  \n",
        "  ys = [np.zeros(N, dtype=np.int32) for _ in range(3)]\n",
        "  \n",
        "  for i, seq in enumerate(pointing_seqs):\n",
        "    if dagesh in seq:\n",
        "      ys[0][i] = 1\n",
        "    if shin in seq:\n",
        "      ys[1][i] = 1\n",
        "    elif sin in seq:\n",
        "      ys[1][i] = 2\n",
        "    \n",
        "    flag = False\n",
        "    for j, diph in enumerate(diphthongs):\n",
        "      if diph in seq:\n",
        "        ys[2][i] = j + num_pointings + 1\n",
        "        flag = True\n",
        "        break\n",
        "    if flag:\n",
        "      continue\n",
        "      \n",
        "    for j, point in enumerate(pointings):\n",
        "      if point in seq:\n",
        "        if ys[2][i] != 0:\n",
        "          print(point)\n",
        "        \n",
        "        ys[2][i] = j + 1\n",
        "        \n",
        "  return X, ys\n",
        "  \n",
        "X, ys = tensorize(text)\n",
        "print(X[:100])\n",
        "ys[2][:120]"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', 'ְּ', 'ֵ', '', 'ִׁ', '', '', '', 'ָּ', 'ָ', '', '', 'ֱ', 'ֹ', 'ִ', '', '', '', 'ֵ', '', '', 'ַ', 'ָּׁ', 'ַ', 'ִ', '', '', 'ְ', 'ֵ', '', '', 'ָ', 'ָ', 'ֶ', '', '', 'ְ', 'ָ', 'ָ', 'ֶ', '', '', 'ָ', 'ְ', 'ָ', '', '', 'ֹ', '', 'ּ', '', 'ָ', 'ֹ', '', 'ּ', '', 'ְ', 'ֹ', 'ֶׁ', 'ְ', '', 'ַ', '', '', 'ְּ', 'ֵ', '', '', 'ְ', '', 'ֹ', '', '', 'ְ', '', 'ּ', 'ַ', '', 'ֱ', 'ֹ', 'ִ', '', '', '', 'ְ', 'ַ', 'ֶ', 'ֶ', '', '', 'ַ', '', '', 'ְּ', 'ֵ', '', '', 'ַ', 'ָּ', 'ִ']\n",
            "[' ', 'ב', 'ר', 'א', 'ש', 'י', 'ת', ' ', 'ב', 'ר', 'א', ' ', 'א', 'ל', 'ה', 'י', 'ם', ' ', 'א', 'ת', ' ', 'ה', 'ש', 'מ', 'י', 'ם', ' ', 'ו', 'א', 'ת', ' ', 'ה', 'א', 'ר', 'ץ', ' ', 'ו', 'ה', 'א', 'ר', 'ץ', ' ', 'ה', 'י', 'ת', 'ה', ' ', 'ת', 'ה', 'ו', ' ', 'ו', 'ב', 'ה', 'ו', ' ', 'ו', 'ח', 'ש', 'ך', ' ', 'ע', 'ל', ' ', 'פ', 'נ', 'י', ' ', 'ת', 'ה', 'ו', 'ם', ' ', 'ו', 'ר', 'ו', 'ח', ' ', 'א', 'ל', 'ה', 'י', 'ם', ' ', 'מ', 'ר', 'ח', 'פ', 'ת', ' ', 'ע', 'ל', ' ', 'פ', 'נ', 'י', ' ', 'ה', 'מ', 'י']\n",
            "12\n",
            "[ 0  2 25  1 26 10 27  0  2 25  1  0  1 13  5 10 14  0  1 27  0  5 26 15\n",
            " 10 14  0  6  1 27  0  5  1 25 22  0  6  5  1 25 22  0  5 10 27  5  0 27\n",
            "  5  6  0  6  2  5  6  0  6  8 26 11  0 19 13  0 21 17 10  0 27  5  6 14\n",
            "  0  6 25  6  8  0  1 13  5 10 14  0 15 25  8 21 27  0 19 13  0 21 17 10\n",
            "  0  5 15 10]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  6,  0,  5,  0,  0,  0,  9,  9,  0,  0,  2, 10,  5,  0,  0,\n",
              "        0,  6,  0,  0,  8,  9,  8,  5,  0,  0,  1,  6,  0,  0,  9,  9,  7,\n",
              "        0,  0,  1,  9,  9,  7,  0,  0,  9,  1,  9,  0,  0, 10,  0,  0,  0,\n",
              "        9, 10,  0,  0,  0,  1, 10,  7,  1,  0,  8,  0,  0,  1,  6,  0,  0,\n",
              "        1,  0, 10,  0,  0,  1,  0,  0,  8,  0,  2, 10,  5,  0,  0,  0,  1,\n",
              "        8,  7,  7,  0,  0,  8,  0,  0,  1,  6,  0,  0,  8,  9,  5,  0,  0,\n",
              "        8, 10,  0,  7,  0,  0,  2, 10,  5,  0,  0,  0,  1,  5,  0,  0,  0,\n",
              "       10], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "metadata": {
        "id": "5UgA7K4ACtwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7b58739-47bb-44ec-ade8-de5a4f3cdf59"
      },
      "cell_type": "code",
      "source": [
        "num_letters = max(X)\n",
        "num_pointings = [max(y) for y in ys]\n",
        "num_letters, num_pointings"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27, [1, 2, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "metadata": {
        "id": "M5qIoEVw-05f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "715895eb-cb37-484f-8be9-af29741956d1"
      },
      "cell_type": "code",
      "source": [
        "seqlen = 60\n",
        "def create_graph(seqlen=seqlen, insize=num_letters, outsize=num_pointings[2]+1, nhidden=64):\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default():\n",
        "    \n",
        "    X = tf.placeholder(tf.int64, shape=(None, seqlen), name='X')\n",
        "    y = tf.placeholder(tf.int64, shape=(None, seqlen), name='y')\n",
        "    \n",
        "    X_onehot = tf.one_hot(X, num_letters, name='onehot')\n",
        "    \n",
        "    cell_fw = tf.nn.rnn_cell.LSTMCell(nhidden)\n",
        "    cell_bw = tf.nn.rnn_cell.LSTMCell(nhidden)\n",
        "    \n",
        "    outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, X_onehot, dtype=tf.float32)\n",
        "    print(cell_fw.weights)\n",
        "    outputs = tf.concat(outputs, axis=-1)\n",
        "    \n",
        "    dense = tf.layers.Dense(outsize)\n",
        "    \n",
        "    logits = dense(outputs)\n",
        "    print(dense.weights)\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name='loss')\n",
        "    \n",
        "    lr = tf.placeholder(tf.float32, shape=(), name='lr')\n",
        "    trn_op = tf.train.RMSPropOptimizer(lr, momentum=0.7, name='trn_op').minimize(loss)\n",
        "    \n",
        "    softmax = tf.nn.softmax(logits)\n",
        "    predicts = tf.argmax(softmax, axis=-1, name='predictions')\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicts, y), tf.float64), name='accuracy')\n",
        "    \n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "    tf.add_to_collections(['train feeds', 'test feeds'], X)\n",
        "    tf.add_to_collections(['train feeds', 'test feeds'], y)\n",
        "    tf.add_to_collection('train feeds', lr)\n",
        "    \n",
        "    tf.add_to_collection('fetches', trn_op)\n",
        "    tf.add_to_collection('fetches', loss)\n",
        "    tf.add_to_collection('fetches', accuracy)\n",
        "  \n",
        "  return graph\n",
        "graph = create_graph()\n"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(91, 256) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/fw/lstm_cell/bias:0' shape=(256,) dtype=float32_ref>]\n",
            "[<tf.Variable 'dense/kernel:0' shape=(128, 17) dtype=float32_ref>, <tf.Variable 'dense/bias:0' shape=(17,) dtype=float32_ref>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v4Sz5tR5avsr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_graph_with_numcheck(seqlen=seqlen, insize=num_letters, outsize=num_pointings[2], nhidden=64):\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default():\n",
        "    \n",
        "    X = tf.placeholder(tf.int64, shape=(None, seqlen), name='X')\n",
        "    y = tf.placeholder(tf.int64, shape=(None, seqlen), name='y')\n",
        "    \n",
        "    X_onehot = tf.one_hot(X, num_letters, name='onehot')\n",
        "    \n",
        "    cell_fw = tf.nn.rnn_cell.LSTMCell(nhidden)\n",
        "    cell_bw = tf.nn.rnn_cell.LSTMCell(nhidden)\n",
        "    \n",
        "    outputs, states = tf.check_numerics(tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, X_onehot, dtype=tf.float32))\n",
        "    print(cell_fw.weights)\n",
        "    outputs = tf.concat(outputs, axis=-1)\n",
        "    \n",
        "    dense = tf.layers.Dense(outsize)\n",
        "    \n",
        "    logits = dense(outputs)\n",
        "    print(dense.weights)\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name='loss')\n",
        "    \n",
        "    lr = tf.placeholder(tf.float32, shape=(), name='lr')\n",
        "    trn_op = tf.train.RMSPropOptimizer(lr, momentum=0.7, name='trn_op').minimize(loss)\n",
        "    \n",
        "    softmax = tf.nn.softmax(logits)\n",
        "    predicts = tf.argmax(softmax, axis=-1, name='predictions')\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicts, y), tf.float64), name='accuracy')\n",
        "    \n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "    tf.add_to_collections(['train feeds', 'test feeds'], X)\n",
        "    tf.add_to_collections(['train feeds', 'test feeds'], y)\n",
        "    tf.add_to_collection('train feeds', lr)\n",
        "    \n",
        "    tf.add_to_collection('fetches', trn_op)\n",
        "    tf.add_to_collection('fetches', loss)\n",
        "    tf.add_to_collection('fetches', accuracy)\n",
        "  \n",
        "  return graph\n",
        "graph = create_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9mH-O365HW7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "371a3e79-7815-48fc-de16-61dbdb3fbd96"
      },
      "cell_type": "code",
      "source": [
        "def batch_gen(bs=64, X=X, y=ys[2], seqlen=seqlen, step=9):\n",
        "  N = len(X)\n",
        "  i = 0\n",
        "  while step*(i+1)*bs+seqlen <= N:\n",
        "    x_batch = [X[step*(i*bs+j):step*(i*bs+j)+seqlen] for j in range(bs)]\n",
        "    y_batch = [y[step*(i*bs+j):step*(i*bs+j)+seqlen] for j in range(bs)]\n",
        "    yield i, x_batch, y_batch\n",
        "    i += 1\n",
        "print(X[:10])\n",
        "print(ys[2][:10])"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  2 25  1 26 10 27  0  2 25]\n",
            "[0 1 6 0 5 0 0 0 9 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rFja2SqPPiPQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f08265df-a880-4e1a-b4b1-0ea729934a7e"
      },
      "cell_type": "code",
      "source": [
        "graph = create_graph()\n",
        "with graph.as_default():\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    gen = batch_gen(X=X, y=ys[2])\n",
        "    for _ in range(10):\n",
        "      _, bx, by = next(gen)\n",
        "      feed = {graph.get_tensor_by_name('X:0'):bx, graph.get_tensor_by_name('y:0'):by}\n",
        "      print(sess.run(graph.get_tensor_by_name('loss:0'), feed_dict = feed))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.761125\n",
            "2.7642653\n",
            "2.7586205\n",
            "2.7551486\n",
            "2.7621267\n",
            "2.7657428\n",
            "2.7588878\n",
            "2.7640033\n",
            "2.762014\n",
            "2.7645266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J_LRVAq1ejJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6b88b76-0c3d-4023-cf27-d8df32f04b3e"
      },
      "cell_type": "code",
      "source": [
        "max(ys[2])"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "metadata": {
        "id": "P12L0rvcHWlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "cb94293f-c112-4e03-d739-17b9f2d65c32"
      },
      "cell_type": "code",
      "source": [
        "def find_lr(graph, batch_gen, start=1e-6, end=1e1, fac=2.0):\n",
        "  lr = start\n",
        "  lrs, losses = [], []\n",
        "  with graph.as_default():\n",
        "    print(tf.get_collection('feeds'))\n",
        "    with tf.Session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      while lr<end:\n",
        "        _, bx, by = next(batch_gen)\n",
        "        feed = dict(zip(tf.get_collection('feeds'), [bx, by, lr]))\n",
        "        fetches = tf.get_collection('fetches')\n",
        "        _, loss, acc = sess.run(fetches, feed_dict=feed)\n",
        "        print(lr, loss, acc)\n",
        "        lr *= fac\n",
        "\n",
        "find_lr(create_graph(), batch_gen(X=X, y=ys[2]))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor 'X:0' shape=(?, 60) dtype=int64>, <tf.Tensor 'y:0' shape=(?, 60) dtype=int64>, <tf.Tensor 'lr:0' shape=() dtype=float32>]\n",
            "1e-06 2.7692735 0.11223958333333334\n",
            "2e-06 2.7697551 0.08619791666666667\n",
            "4e-06 2.771639 0.10260416666666666\n",
            "8e-06 2.780276 0.071875\n",
            "1.6e-05 2.7745478 0.07578125\n",
            "3.2e-05 2.777519 0.05859375\n",
            "6.4e-05 2.77338 0.07109375\n",
            "0.000128 2.7743814 0.058333333333333334\n",
            "0.000256 2.7728999 0.08229166666666667\n",
            "0.000512 2.7742593 0.06927083333333334\n",
            "0.001024 2.7752347 0.06536458333333334\n",
            "0.002048 2.7741735 0.06302083333333333\n",
            "0.004096 2.7734103 0.07578125\n",
            "0.008192 2.7669008 0.11223958333333334\n",
            "0.016384 2.7531993 0.14739583333333334\n",
            "0.032768 2.7226083 0.32005208333333335\n",
            "0.065536 2.6842015 0.46979166666666666\n",
            "0.131072 2.5872757 0.4796875\n",
            "0.262144 2.380978 0.49140625\n",
            "0.524288 2.0110328 0.4859375\n",
            "1.048576 2.0723639 0.46979166666666666\n",
            "2.097152 3.0380487 0.1015625\n",
            "4.194304 2.8138301 0.0734375\n",
            "8.388608 16.797659 0.5015625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ar5AvMlsHWgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "0fe0e6b6-4978-4726-e7f9-9a71dc0a7602"
      },
      "cell_type": "code",
      "source": [
        "def train_epoch(graph, gen, lr, epochs):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      tf.summary.FileWriter('/log', graph=graph, session=sess)\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      for ie in range(epochs):\n",
        "        ac_loss, ac_acc = 0, 0\n",
        "        for ib, bx, by in gen():\n",
        "          feed = dict(zip(tf.get_collection('train feeds'), [bx, by, lr]))\n",
        "          _, loss, acc = sess.run(tf.get_collection('fetches'), feed_dict=feed)\n",
        "          ac_loss += loss\n",
        "          ac_acc += acc\n",
        "          if ib%100==0 and ib>0:\n",
        "            print(\"epoch {}, batch {} - loss: {}, accuracy: {}\".format(ie, ib, ac_loss/100, ac_acc/100))\n",
        "            ac_loss, ac_acc = 0, 0\n",
        "\n",
        "train_epoch(create_graph(), lambda: batch_gen(bs=256), 0.1, 3)\n"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(91, 256) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/fw/lstm_cell/bias:0' shape=(256,) dtype=float32_ref>]\n",
            "[<tf.Variable 'dense/kernel:0' shape=(128, 17) dtype=float32_ref>, <tf.Variable 'dense/bias:0' shape=(17,) dtype=float32_ref>]\n",
            "epoch 0, batch 100 - loss: 1.5387536084651947, accuracy: 0.5350065104166665\n",
            "epoch 0, batch 200 - loss: 0.7017419761419297, accuracy: 0.7634205729166671\n",
            "epoch 0, batch 300 - loss: 0.5886567836999893, accuracy: 0.8021699218750001\n",
            "epoch 0, batch 400 - loss: 0.5599243578314781, accuracy: 0.8138424479166666\n",
            "epoch 1, batch 100 - loss: 0.5764878943562508, accuracy: 0.8179550781250002\n",
            "epoch 1, batch 200 - loss: 0.5260412582755088, accuracy: 0.8293450520833333\n",
            "epoch 1, batch 300 - loss: 0.547517860531807, accuracy: 0.815047526041667\n",
            "epoch 1, batch 400 - loss: 0.529580470919609, accuracy: 0.8223255208333333\n",
            "epoch 2, batch 100 - loss: 0.5458904957771301, accuracy: 0.8286822916666668\n",
            "epoch 2, batch 200 - loss: 0.5022823822498321, accuracy: 0.8376223958333335\n",
            "epoch 2, batch 300 - loss: 0.5292867004871369, accuracy: 0.8202903645833328\n",
            "epoch 2, batch 400 - loss: 0.5110459032654763, accuracy: 0.8292871093749998\n",
            "epoch 3, batch 100 - loss: 0.5315536665916443, accuracy: 0.8333274739583336\n",
            "epoch 3, batch 200 - loss: 0.49265102207660677, accuracy: 0.8396269531249999\n",
            "epoch 3, batch 300 - loss: 0.5196632206439972, accuracy: 0.8241119791666668\n",
            "epoch 3, batch 400 - loss: 0.5042744514346122, accuracy: 0.8312656250000002\n",
            "epoch 4, batch 100 - loss: 0.5268291446566582, accuracy: 0.8367968749999997\n",
            "epoch 4, batch 200 - loss: 0.4822148936986923, accuracy: 0.8433177083333335\n",
            "epoch 4, batch 300 - loss: 0.514253378212452, accuracy: 0.8268522135416667\n",
            "epoch 4, batch 400 - loss: 0.5018031305074692, accuracy: 0.8337454427083335\n",
            "epoch 5, batch 100 - loss: 0.5125912627577782, accuracy: 0.8394908854166669\n",
            "epoch 5, batch 200 - loss: 0.4764773988723755, accuracy: 0.8472760416666665\n",
            "epoch 5, batch 300 - loss: 0.5099786603450776, accuracy: 0.8275735677083336\n",
            "epoch 5, batch 400 - loss: 0.49606829464435576, accuracy: 0.8355983072916666\n",
            "epoch 6, batch 100 - loss: 0.5272864347696304, accuracy: 0.8357076822916667\n",
            "epoch 6, batch 200 - loss: 0.48156233102083207, accuracy: 0.8445071614583333\n",
            "epoch 6, batch 300 - loss: 0.5137231194972992, accuracy: 0.8272942708333336\n",
            "epoch 6, batch 400 - loss: 0.497777940928936, accuracy: 0.835025390625\n",
            "epoch 7, batch 100 - loss: 0.5177525264024735, accuracy: 0.8384016927083331\n",
            "epoch 7, batch 200 - loss: 0.4742752230167389, accuracy: 0.8457187500000002\n",
            "epoch 7, batch 300 - loss: 0.5123864668607712, accuracy: 0.8285240885416666\n",
            "epoch 7, batch 400 - loss: 0.49154366880655287, accuracy: 0.8365944010416666\n",
            "epoch 8, batch 100 - loss: 0.5078615936636924, accuracy: 0.8410514322916669\n",
            "epoch 8, batch 200 - loss: 0.47033768236637113, accuracy: 0.8476894531250002\n",
            "epoch 8, batch 300 - loss: 0.5069854521751403, accuracy: 0.8296028645833334\n",
            "epoch 8, batch 400 - loss: 0.4913375300168991, accuracy: 0.8371575520833332\n",
            "epoch 9, batch 100 - loss: 0.5032217907905578, accuracy: 0.8427851562500004\n",
            "epoch 9, batch 200 - loss: 0.46430467516183854, accuracy: 0.8508411458333336\n",
            "epoch 9, batch 300 - loss: 0.4997410413622856, accuracy: 0.8326770833333336\n",
            "epoch 9, batch 400 - loss: 0.48571936070919036, accuracy: 0.8384069010416672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZbxejqImyCE-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(graph, gen):\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AxGfGEu0sUz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "5f254768-fb1d-434d-d1de-20a167f61c77"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-07-11 10:37:51--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\r\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.1.117.85, 34.206.253.53, 52.20.145.121, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.1.117.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  7.61MB/s    in 0.7s    \n",
            "\n",
            "2018-07-11 10:37:53 (7.61 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rnxGwkrG6XL3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HgD0-zrz6e8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "181b720e-6cda-47f8-914c-a2a3ac78a7a6"
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://e04d930f.ngrok.io\r\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}